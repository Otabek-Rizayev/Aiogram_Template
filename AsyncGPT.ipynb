{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "name": "AsyncGPT.ipynb",
      "authorship_tag": "ABX9TyObrLZJ0jUT5mCyv7obrmfx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Otabek-Rizayev/Aiogram_Template/blob/main/AsyncGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU datasets pinecone-client sentence-transformers torch"
      ],
      "metadata": {
        "id": "7WVWJhxGG6MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "wiki_data = load_dataset(\n",
        "    'vblagoje/wikipedia_snippets_streamed',\n",
        "    split='train',\n",
        "    streaming=True\n",
        ").shuffle(seed=960)"
      ],
      "metadata": {
        "id": "4zyNRceuzA_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(wiki_data))"
      ],
      "metadata": {
        "id": "IUm_pGSRhwTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = wiki_data.filter(\n",
        "    lambda d: d['section_title'].startswith('History')\n",
        ")"
      ],
      "metadata": {
        "id": "gcPNNpD0uBJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "total_doc_count = 50000\n",
        "counter = 0\n",
        "docs = []\n",
        "for d in tqdm(history, total=total_doc_count):\n",
        "  doc = {\n",
        "      \"article_title\": d[\"article_title\"],\n",
        "      \"section_title\": d[\"section_title\"],\n",
        "      \"passage_text\": d[\"passage_text\"]\n",
        "  }\n",
        "  docs.append(doc)\n",
        "  if counter == total_doc_count:\n",
        "    break\n",
        "  counter += 1"
      ],
      "metadata": {
        "id": "Hb1EzjS47Xj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(docs)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "IdESEdFbONG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "pinecone.init(\n",
        "    api_key=\"3adbd7f7-8619-4352-9d13-d54947725b9a\",\n",
        "    environment=\"us-west4-gcp-free\"\n",
        ")"
      ],
      "metadata": {
        "id": "3C5il8M9ONEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"abstractive-question-answering\"\n",
        "\n",
        "if index_name not in pinecone.list_indexes():\n",
        "  pinecone.create_index(\n",
        "      index_name,\n",
        "      dimension=768,\n",
        "      metric=\"cosine\",\n",
        "  )\n",
        "index = pinecone.Index(index_name)"
      ],
      "metadata": {
        "id": "Q1OKTNzbOM5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "retriever = SentenceTransformer(\n",
        "    \"flax-sentence-embeddings/all_datasets_v3_mpnet-base\",\n",
        "    device=device\n",
        ")\n",
        "retriever"
      ],
      "metadata": {
        "id": "XMWBwTAxOMyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "for i in tqdm(range(0, len(df), batch_size)):\n",
        "  i_end = min(i+batch_size, len(df))\n",
        "  batch = df.iloc[i:i_end]\n",
        "  emb = retriever.encode(batch[\"passage_text\"].tolist()).tolist()\n",
        "  meta = batch.to_dict(orient=\"records\")\n",
        "  ids = [f\"{idx}\" for idx in range(i, i_end)]\n",
        "  to_upsert = list(zip(ids, emb, meta))\n",
        "  _ = index.upsert(vectors=to_upsert)\n",
        "\n",
        "index.describe_index_stats()\n"
      ],
      "metadata": {
        "id": "cumZdxQVOMsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained(\"vblagoje/bart_lfqa\")\n",
        "generator = BartForConditionalGeneration.from_pretrained(\"vblagoje/bart_lfqa\")"
      ],
      "metadata": {
        "id": "NaBQX_kGnlLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_pinecone(query, top_k):\n",
        "  xq = retriever.encode([query]).tolist()\n",
        "  xc = index.query(xq, top_k=top_k, include_metadata=True)\n",
        "  return xc"
      ],
      "metadata": {
        "id": "qSVdVUXanlV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_query(query, context):\n",
        "  context = [f\"<P> {m['metadata']['passage_text']}\" for m in context]\n",
        "  context = \" \".join(context)\n",
        "  query = f\"Question: {query}\\n context: {context}\"\n",
        "  return query"
      ],
      "metadata": {
        "id": "ho9gLd3AnlYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is it Python?\"\n",
        "result = query_pinecone(query, top_k=1)\n",
        "result"
      ],
      "metadata": {
        "id": "SzjYCimfnlba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "query = format_query(query, result['matches'])\n",
        "pprint(query)"
      ],
      "metadata": {
        "id": "tizu_2fFnleW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(query):\n",
        "  inputs = tokenizer([query], max_length=1024, return_tensors='pt')\n",
        "  ids = generator.generate(\n",
        "      inputs['input_ids'], num_beams=2, min_length=20, max_length=40\n",
        "  )\n",
        "  answer = tokenizer.batch_decode(ids, skip_special_tokens=True, clean_up_tokenization=False)[0]\n",
        "  return pprint(answer)"
      ],
      "metadata": {
        "id": "HF0hIycvnlgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_answer(query)"
      ],
      "metadata": {
        "id": "heR2O6T-nljK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Elon Musk's first project?\"\n",
        "context = query_pinecone(query, top_k=5)\n",
        "query = format_query(query, context['matches'])\n",
        "generate_answer(query)"
      ],
      "metadata": {
        "id": "MFCC69YNVzr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in context[\"matches\"]:\n",
        "  print(doc[\"metadata\"][\"passage_text\"], end='\\n---\\n')\n"
      ],
      "metadata": {
        "id": "pB9z8ncexQkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What was Nasas most expensive project?\"\n",
        "context = query_pinecone(query, top_k=3)\n",
        "query = format_query(query, context[\"matches\"])\n",
        "generate_answer(query)"
      ],
      "metadata": {
        "id": "qyCd_Z_wxzoK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}